{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fa = pd.read_csv('/home/syb/Code/coupling/python/file/data/SDI_sub/sc_mode_1.csv')\n",
    "df_md = pd.read_csv('/home/syb/Code/coupling/python/file/data/SDI_sub/sc_mode_2.csv')\n",
    "df_num = pd.read_csv('/home/syb/Code/coupling/python/file/data/SDI_sub/sc_mode_3.csv')\n",
    "df_label = pd.read_csv('/home/syb/Code/coupling/python/file/data/sc_mode_label.csv')\n",
    "df_info = pd.read_csv('/home/syb/Code/coupling/python/file/data/sc_mode_info.csv')\n",
    "df_mode= [df_fa,df_md,df_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[28. 28. 29. 29. 29. 30. 29. 27. 28. 29. 29. 29. 27. 24. 28. 28. 28. 30.\n 26. 30. 30. 30. 30. 26. 29. 28. 30. 30. 30. 29. 29. 27. 30. 28. 28. 26.\n 29. 29. 27. 30. 30. 29. 29. 25. 27. 30. 27. 30. 23. 21. 26. 28. 27. 29.\n 28. 29. 26. 29. 22. 25. 27. 28. 29. 29. 23. 25. 24. 29. 27. 29. 23. 27.\n 24. 24. 27. 26. 22. 18. 19. 23. 15. 23.  5. 23. 12. 13. 24. 15. 22. 25.\n 17. 22. 16. 21. 27. 26. 23. 19. 25.  5. 18. 22.  7.  7. 15. 17. 20. 19.\n 13.  6. 18.  9. 11.  3. 13. 13. 20. 23. 23. 29. 30. 29. 30. 29. 30. 29.\n 28. 29. 30. 29. 26. 28. 27. 28. 30. 29. 30. 29. 28. 30. 27. 25. 26. 28.\n 28. 30. 22. 28. 26. 29. 26. 27. 24. 28. 29. 28. 28. 26. 29. 27. 28. 27.\n 25. 25. 21. 17. 19. 22. 22. 18. 12. 23. 16. 15.  6. 20. 20. 26. 13. 22.\n 26. 19. 22. 16. 20. 22. 18. 29. 28. 27. 30. 30. 30. 30. 29. 29. 27. 30.\n 30. 29. 28. 29. 28. 30. 27. 27. 30. 27. 29. 28. 29. 26. 28. 30. 23. 23.\n 23. 23. 25. 27. 24. 22. 28. 26. 21. 24. 27. 27. 26. 27. 28. 29. 25. 30.\n 28. 27. 30. 26. 26. 28. 23. 23. 24. 29. 12. 22. 20.  9. 24. 12. 22. 19.\n 16.  1.  9. 14. 21. 12. 16. 15. 19.  8. 23. 16.  6. 19. 10.  8. 13. 11.\n 18. 20. 17. 17. 24. 14. 20. 20. 19. 22. 18. 27. 28. 29. 26. 30. 26. 30.\n 26. 29. 29. 30. 27. 30. 28. 30. 28. 27. 30. 23. 28. 26. 30. 26. 30. 30.\n 27. 30. 28. 30. 28. 30. 30. 27. 30. 30. 30. 29. 26. 30. 28. 30. 30. 27.\n 25. 27. 27. 25. 23. 24. 24. 23. 27. 23. 24. 24. 24. 24. 26. 23. 22. 24.\n 12. 18. 26. 24. 26. 24. 17. 20. 19. 20. 13. 21. 16. 22. 16. 19. 15. 18.\n 22. 16. 22. 15. 19. 19. 20. 20. 20. 13. 22. 16. 20. 19. 21. 12. 13. 22.\n 16. 21. 21. 18. 21. 21. 16. 17. 15. 16. 21. 16. 17. 16. 15. 21. 16. 21.\n 16. 15. 21. 22. 25. 19. 20. 19. 18. 30. 29. 30. 30. 30. 30. 30. 27. 29.\n 26. 30. 27. 27. 27. 29. 29. 27. 30. 30. 29. 29. 24. 30. 26. 27. 29. 27.\n 26. 24. 29. 28. 29. 26. 29. 22. 28. 23. 20. 30. 24. 30. 27. 28. 30. 30.\n 30. 30. 28. 30. 30. 27. 27. 30. 30. 30. 30. 30. 30. 26. 28. 30. 29. 28.\n 26. 23. 21. 23. 18. 26. 23. 23. 23. 25. 26. 17. 29. 25. 26. 27. 24. 25.\n 23. 17. 28. 24. 27. 27. 27. 29. 26. 23. 18. 23. 24. 26. 30. 27. 22. 21.\n 27. 29. 28. 30. 25. 29. 30. 20. 27. 28. 15. 28. 28. 28. 28. 27. 25. 29.\n 25. 27. 17. 18. 23. 27. 20. 21. 29. 26. 22. 24. 28. 23. 27. 21. 22. 23.\n 17. 24. 26. 25. 19. 18. 23. 23. 27. 23. 17. 15. 26. 24. 22. 24. 20. 21.\n 24. 25. 26. 23. 21. 18. 17. 19. 14. 12.  6. 13. 13. 13. 19. 24. 21. 16.\n 14. 24. 21.  3. 22.  9. 24. 17. 20. 17. 23. 29. 20. 19. 19. 23. 24. 26.\n 20.  5.  4. 12.  6.  5. 17. 28. 29. 29. 27. 28. 28. 30. 29. 28. 30. 29.\n 29. 29. 28. 30. 29. 24. 28. 29. 30. 27. 22. 27. 17.  9. 24. 27. 22. 26.\n 19. 15. 24. 24. 23. 18. 28. 27. 25. 18.  2. 16.  9.  0.  7.  0.  1. 17.\n 14.  8. 13. 23. 13.  1.  9.  0.  9. 13.  2. 22. 13. 10. 25. 13. 12.  8.\n 20.  8.  6.  8. 15. 11.  3. 29. 29. 30. 29. 28. 29. 29. 30. 29. 29. 27.\n 29. 27. 28. 29. 29. 29. 26. 28. 29. 29. 30. 28. 30. 25. 30. 30. 27. 29.\n 29. 29. 30. 26. 30. 30. 29. 30. 29. 28. 29. 30. 30. 29. 27. 26. 24. 25.\n 28. 23. 26. 28. 27. 30. 27. 23. 27. 25. 27. 27. 29. 30. 19. 27. 28. 29.\n 23. 22. 28. 27. 27. 21. 30. 23. 27. 27. 27. 24. 28. 27. 22. 24. 21. 21.\n 21. 10.  8. 12. 22. 10. 21. 20. 16. 13. 15.  9. 14. 13. 14. 23. 18. 17.\n  7. 15. 11.  8. 15. 25.  8. 20. 12. 18.  5. 11. 16. 22.  5. 19. 22. 23.\n 23.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31130/1824717054.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_fa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 将标签归一化到0,1之间\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mmse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 将特征归于化到0,1之间\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 将数据恢复至归一化之前\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         )\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                     \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m                 )\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[28. 28. 29. 29. 29. 30. 29. 27. 28. 29. 29. 29. 27. 24. 28. 28. 28. 30.\n 26. 30. 30. 30. 30. 26. 29. 28. 30. 30. 30. 29. 29. 27. 30. 28. 28. 26.\n 29. 29. 27. 30. 30. 29. 29. 25. 27. 30. 27. 30. 23. 21. 26. 28. 27. 29.\n 28. 29. 26. 29. 22. 25. 27. 28. 29. 29. 23. 25. 24. 29. 27. 29. 23. 27.\n 24. 24. 27. 26. 22. 18. 19. 23. 15. 23.  5. 23. 12. 13. 24. 15. 22. 25.\n 17. 22. 16. 21. 27. 26. 23. 19. 25.  5. 18. 22.  7.  7. 15. 17. 20. 19.\n 13.  6. 18.  9. 11.  3. 13. 13. 20. 23. 23. 29. 30. 29. 30. 29. 30. 29.\n 28. 29. 30. 29. 26. 28. 27. 28. 30. 29. 30. 29. 28. 30. 27. 25. 26. 28.\n 28. 30. 22. 28. 26. 29. 26. 27. 24. 28. 29. 28. 28. 26. 29. 27. 28. 27.\n 25. 25. 21. 17. 19. 22. 22. 18. 12. 23. 16. 15.  6. 20. 20. 26. 13. 22.\n 26. 19. 22. 16. 20. 22. 18. 29. 28. 27. 30. 30. 30. 30. 29. 29. 27. 30.\n 30. 29. 28. 29. 28. 30. 27. 27. 30. 27. 29. 28. 29. 26. 28. 30. 23. 23.\n 23. 23. 25. 27. 24. 22. 28. 26. 21. 24. 27. 27. 26. 27. 28. 29. 25. 30.\n 28. 27. 30. 26. 26. 28. 23. 23. 24. 29. 12. 22. 20.  9. 24. 12. 22. 19.\n 16.  1.  9. 14. 21. 12. 16. 15. 19.  8. 23. 16.  6. 19. 10.  8. 13. 11.\n 18. 20. 17. 17. 24. 14. 20. 20. 19. 22. 18. 27. 28. 29. 26. 30. 26. 30.\n 26. 29. 29. 30. 27. 30. 28. 30. 28. 27. 30. 23. 28. 26. 30. 26. 30. 30.\n 27. 30. 28. 30. 28. 30. 30. 27. 30. 30. 30. 29. 26. 30. 28. 30. 30. 27.\n 25. 27. 27. 25. 23. 24. 24. 23. 27. 23. 24. 24. 24. 24. 26. 23. 22. 24.\n 12. 18. 26. 24. 26. 24. 17. 20. 19. 20. 13. 21. 16. 22. 16. 19. 15. 18.\n 22. 16. 22. 15. 19. 19. 20. 20. 20. 13. 22. 16. 20. 19. 21. 12. 13. 22.\n 16. 21. 21. 18. 21. 21. 16. 17. 15. 16. 21. 16. 17. 16. 15. 21. 16. 21.\n 16. 15. 21. 22. 25. 19. 20. 19. 18. 30. 29. 30. 30. 30. 30. 30. 27. 29.\n 26. 30. 27. 27. 27. 29. 29. 27. 30. 30. 29. 29. 24. 30. 26. 27. 29. 27.\n 26. 24. 29. 28. 29. 26. 29. 22. 28. 23. 20. 30. 24. 30. 27. 28. 30. 30.\n 30. 30. 28. 30. 30. 27. 27. 30. 30. 30. 30. 30. 30. 26. 28. 30. 29. 28.\n 26. 23. 21. 23. 18. 26. 23. 23. 23. 25. 26. 17. 29. 25. 26. 27. 24. 25.\n 23. 17. 28. 24. 27. 27. 27. 29. 26. 23. 18. 23. 24. 26. 30. 27. 22. 21.\n 27. 29. 28. 30. 25. 29. 30. 20. 27. 28. 15. 28. 28. 28. 28. 27. 25. 29.\n 25. 27. 17. 18. 23. 27. 20. 21. 29. 26. 22. 24. 28. 23. 27. 21. 22. 23.\n 17. 24. 26. 25. 19. 18. 23. 23. 27. 23. 17. 15. 26. 24. 22. 24. 20. 21.\n 24. 25. 26. 23. 21. 18. 17. 19. 14. 12.  6. 13. 13. 13. 19. 24. 21. 16.\n 14. 24. 21.  3. 22.  9. 24. 17. 20. 17. 23. 29. 20. 19. 19. 23. 24. 26.\n 20.  5.  4. 12.  6.  5. 17. 28. 29. 29. 27. 28. 28. 30. 29. 28. 30. 29.\n 29. 29. 28. 30. 29. 24. 28. 29. 30. 27. 22. 27. 17.  9. 24. 27. 22. 26.\n 19. 15. 24. 24. 23. 18. 28. 27. 25. 18.  2. 16.  9.  0.  7.  0.  1. 17.\n 14.  8. 13. 23. 13.  1.  9.  0.  9. 13.  2. 22. 13. 10. 25. 13. 12.  8.\n 20.  8.  6.  8. 15. 11.  3. 29. 29. 30. 29. 28. 29. 29. 30. 29. 29. 27.\n 29. 27. 28. 29. 29. 29. 26. 28. 29. 29. 30. 28. 30. 25. 30. 30. 27. 29.\n 29. 29. 30. 26. 30. 30. 29. 30. 29. 28. 29. 30. 30. 29. 27. 26. 24. 25.\n 28. 23. 26. 28. 27. 30. 27. 23. 27. 25. 27. 27. 29. 30. 19. 27. 28. 29.\n 23. 22. 28. 27. 27. 21. 30. 23. 27. 27. 27. 24. 28. 27. 22. 24. 21. 21.\n 21. 10.  8. 12. 22. 10. 21. 20. 16. 13. 15.  9. 14. 13. 14. 23. 18. 17.\n  7. 15. 11.  8. 15. 25.  8. 20. 12. 18.  5. 11. 16. 22.  5. 19. 22. 23.\n 23.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "\n",
    "# feature_range控制压缩数据范围，默认[0,1]\n",
    "scaler = MinMaxScaler(feature_range=[0,1]) # 实例化，调整0,1的数值可以改变归一化范围\n",
    " \n",
    "X = scaler.fit_transform(df_fa.values)  # 将标签归一化到0,1之间\n",
    "Y = scaler.fit_transform(df_info['mmse'].values)  # 将特征归于化到0,1之间\n",
    " \n",
    "x = scaler.inverse_transform(X) # 将数据恢复至归一化之前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    " \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_output, n_neuron1, n_neuron2,n_layer):  # n_feature为特征数目，这个数字不能随便取,n_output为特征对应的输出数目，也不能随便取\n",
    "        self.n_feature=n_feature\n",
    "        self.n_output=n_output\n",
    "        self.n_neuron1=n_neuron1\n",
    "        self.n_neuron2=n_neuron2\n",
    "        self.n_layer=n_layer\n",
    "        super(Net, self).__init__()\n",
    "        self.input_layer = torch.nn.Linear(self.n_feature, self.n_neuron1) # 输入层\n",
    "        self.hidden1 = torch.nn.Linear(self.n_neuron1, self.n_neuron2) # 1类隐藏层    \n",
    "        self.hidden2 = torch.nn.Linear(self.n_neuron2, self.n_neuron2) # 2类隐藏\n",
    "        self.predict = torch.nn.Linear(self.n_neuron2, self.n_output) # 输出层\n",
    " \n",
    "    def forward(self, x):\n",
    "        '''定义前向传递过程'''\n",
    "        out = self.input_layer(x)\n",
    "        out = torch.relu(out) # 使用relu函数非线性激活\n",
    "        out = self.hidden1(out)\n",
    "        out = torch.relu(out)\n",
    "        for i in range(self.n_layer-1):\n",
    "            out = self.hidden2(out)\n",
    "            out = torch.relu(out) \n",
    "\n",
    "        out = self.hidden2(out)\n",
    "        out = self.predict( # 回归问题最后一层不需要激活函数\n",
    "            out\n",
    "        )  # 除去feature_number与out_prediction不能随便取，隐藏层数与其他神经元数目均可以适当调整以得到最佳预测效果\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''训练部分'''\n",
    "\n",
    "def MTrain(train_data):\n",
    "    feature_number = 13  # 设置特征数目\n",
    "    out_prediction = 1  # 设置输出数目\n",
    "    learning_rate = 0.01  # 设置学习率\n",
    "    epochs = 50  # 设置训练代数\n",
    "    net = Net(n_feature=feature_number,\n",
    "                        n_output=out_prediction,\n",
    "                        n_layer=1,\n",
    "                        n_neuron1=20,\n",
    "                        n_neuron2=20) # 这里直接确定了隐藏层数目以及神经元数目，实际操作中需要遍历\n",
    "    optimizer = optim.Adam(net.parameters(), learning_rate)  # 使用Adam算法更新参数\n",
    "    criteon = torch.nn.MSELoss()  # 误差计算公式，回归问题采用均方误差\n",
    "    \n",
    "    for epoch in range(epochs):  # 整个数据集迭代次数\n",
    "        net.train() # 启动训练模式\n",
    "        for batch_idx, (data, target) in enumerate(train_data):\n",
    "            logits = net.forward(data)  # 前向计算结果（预测结果）\n",
    "            loss = criteon(logits, target)  # 计算损失\n",
    "            optimizer.zero_grad()  # 梯度清零\n",
    "            loss.backward()  # 后向传递过程\n",
    "            optimizer.step()  # 优化权重与偏差矩阵\n",
    "    \n",
    "        logit = []  # 这个是验证集，可以根据验证集的结果进行调参，这里根据验证集的结果选取最优的神经网络层数与神经元数目\n",
    "        target = []\n",
    "        net.eval() # 启动测试模式\n",
    "        for data, targets in validation:  # 输出验证集的平均误差\n",
    "            logits = net.forward(data).detach().numpy()\n",
    "            targets=targets.detach().numpy()\n",
    "            target.append(targets[0])\n",
    "            logit.append(logits[0])\n",
    "        average_loss =  criteon(torch.tensor(logit), torch.tensor(target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_re = []\n",
    "y_pred_3 = []\n",
    "y_true_3 = []\n",
    "\n",
    "r_list = []\n",
    "p_list = []\n",
    "mode = 0\n",
    "\n",
    "#计算三种模态各个的分类性能\n",
    "for mode in range(1):\n",
    "    y_pred_mode = []\n",
    "    y_true_mode = []\n",
    "    #fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    #把fa和info合并成一个表格\n",
    "    df_sc1= pd.concat([df_mode[mode],df_info],join=\"outer\",axis=1)\n",
    "    for i in range(7):\n",
    "        center = i+1\n",
    "        df = df_sc1.sample(frac=1).reset_index(drop=True)\n",
    "        #df = df[df['label'] !=2]\n",
    "        #df = df['label'].replace(3,0)\n",
    "        \n",
    "        #df.loc[df['label']==3,'label'] = 0\n",
    "        df_test = df[df['center']== center].drop(axis=1,columns=['center','label'])\n",
    "        df_train = df[df['center'] != center].drop(axis=1,columns=['center','label'])\n",
    "        \n",
    "        y_test = df_test['mmse'].values\n",
    "        y_train = df_train['mmse'].values\n",
    "        x_test = df_test.drop(axis=1,columns=['mmse']).values\n",
    "        x_train = df_train.drop(axis=1,columns=['mmse']).values\n",
    "\n",
    "        \n",
    "      \n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        y_pred_mode.extend(y_pred)\n",
    "        y_true_mode.extend(y_test)\n",
    "        r2_re.append(pearsonr(y_pred,y_test)[0])\n",
    "\n",
    "    y_pred_3.append(y_pred_mode)\n",
    "    y_true_3.append(y_true_mode)\n",
    "    r_list.append(pearsonr(y_pred_mode,y_true_mode)[0])\n",
    "    p_list.append(pearsonr(y_pred_mode,y_true_mode)[0])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    df_y = pd.DataFrame( data= np.transpose([y_pred_mode,y_true_mode]), columns=['pred','true'])\n",
    "    \n",
    "\n",
    "    sns.regplot(data= df_y, x='true',y= 'pred')\n",
    "    \n",
    "    modelName = str(model)\n",
    "\n",
    "    #plt.scatter(y_true_mode,y_pred_mode)\n",
    "\n",
    "    rp = pearsonr(y_pred_mode,y_true_mode)\n",
    "    \n",
    "    \n",
    "    plt.xlim([0,35])\n",
    "    plt.ylim([0,35])\n",
    "    \n",
    "    plt.title(modelName+', r= '+ str(round(rp[0],5)) +', p = '+ str(rp[1]))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
